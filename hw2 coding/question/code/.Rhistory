for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
for(x in predicted_prob){
if(x == 1){
x<- "Up"
}
else x<- "Down"
}
predicted_prob<- as.factor(test.data$predicted_prob)
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
View(test.data)
View(test.data)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume+Today, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(test.data$predicted_prob)
View(test.data)
View(test.data)
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
View(predicted_prob)
predicted_prob<- as.factor(test.data$predicted_prob)
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
confusionMatrix(test.data$predicted_prob, test.data$Direction)
#confusionMatrix(test.data$predicted_prob, test.data$Direction)
mean(predicted_prob == test.data$Direction)
#confusionMatrix(test.data$predicted_prob, test.data$Direction)
mean(test.data$Direction==predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
as.factor(new_direction)
new_direction<- as.factor(new_direction)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume+ Today, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(test.data$predicted_prob)
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(predicted_prob, new_direction)
confusionMatrix(new_direction, predicted_prob)
install.packages('e1071', dependencies=TRUE)
confusionMatrix(new_direction, predicted_prob)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(new_direction, predicted_prob)
logit.model<- glm(Direction~ Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
Lag1 +
Lag1 +
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
anova(logit.model)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume+Today, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(new_direction, predicted_prob)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(new_direction, predicted_prob)
logit.model<- glm(Direction~ Lag1 + Lag2 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
test.data[, test.data$Lag3 <- NULL]
test.data[, test.data$Lag4 <- NULL]
test.data[, test.data$Lag5 <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(new_direction, predicted_prob)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(new_direction, predicted_prob)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.5,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(new_direction, predicted_prob)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
#fit the training data into a logit model for logisitic regression
#data_split<- createDataPartition(y= logistic.df$Direction, p=0.7, list = FALSE)
#train_data<- logistic.df[data_split]
#test_data<- logistic.df[-data_split]
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.45,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
confusionMatrix(new_direction, predicted_prob)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
View(predicted_prob)
View(test.data)
mean(test.data$Direction==predicted_prob)
mean(new_direction==predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.55,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
View(new_direction)
confusionMatrix(new_direction, predicted_prob)
mean(new_direction==predicted_prob)
predicted_prob <- ifelse(predicted_prob > mean(predicted_prob),1,0)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
View(predicted_prob)
threshold<- mean(predicted_prob)
predicted_prob <- ifelse(predicted_prob > threshold,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
View(new_direction)
#View(new_direction)
confusionMatrix(new_direction, predicted_prob)
mean(new_direction==predicted_prob)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
#fit the training data into a logit model for logisitic regression
#data_split<- createDataPartition(y= logistic.df$Direction, p=0.7, list = FALSE)
#train_data<- logistic.df[data_split]
#test_data<- logistic.df[-data_split]
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
threshold<- mean(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.6,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
#View(new_direction)
confusionMatrix(new_direction, predicted_prob)
mean(new_direction==predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.55,1,0)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
#fit the training data into a logit model for logisitic regression
#data_split<- createDataPartition(y= logistic.df$Direction, p=0.7, list = FALSE)
#train_data<- logistic.df[data_split]
#test_data<- logistic.df[-data_split]
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
anova(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
test.data[, test.data$Today <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
#View(predicted_prob)
threshold<- mean(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.55,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
#View(new_direction)
confusionMatrix(new_direction, predicted_prob)
mean(new_direction==predicted_prob)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.75* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume+Today, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
threshold<- mean(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.55,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
#View(new_direction)
confusionMatrix(new_direction, predicted_prob)
logistic.df<<- read.csv("C:\\Rutvik hdd files\\ncsu\\FDS\\HW\\HW23R_Updated\\HW23R\\data\\hw23R-logistic.txt", header = TRUE, stringsAsFactors = TRUE)
logistic.df$Direction <- factor(logistic.df$Direction, levels=c("Down", "Up"), ordered=TRUE)
#calculate the number of rows for the train data in order to split the complete data by 75%
sample_size<- floor(0.70* nrow(logistic.df))
#set the value of seed to repeatedly produce the same samples
set.seed(135)
#split the data into train.data and test.data based on the sample size calculated
training_index <- sample(seq_len(nrow(logistic.df)), size = sample_size)
train.data<-logistic.df[training_index, ]
train.data$Direction<- as.factor(train.data$Direction)
test.data<- logistic.df[-training_index, ]
test.data$Direction<- as.factor(test.data$Direction)
logit.model<- glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 +Volume+Today, family = binomial(link= "logit"), data= train.data)
#summarize the training data to identify the regression coefficients
summary(logit.model)
#remove year column from test data because the model does not have the year column
test.data[, test.data$Year <- NULL]
#predict the probability of the test data being true with respect to the training data and store it in a new column under test.data
predicted_prob <- predict(logit.model, test.data, type= "response")
threshold<- mean(predicted_prob)
predicted_prob <- ifelse(predicted_prob > 0.55,1,0)
predicted_prob<- as.factor(predicted_prob)
new_direction<- ifelse(test.data$Direction == "Up" , 1,0)
new_direction<- as.factor(new_direction)
#View(new_direction)
confusionMatrix(new_direction, predicted_prob)
mean(new_direction==predicted_prob)
